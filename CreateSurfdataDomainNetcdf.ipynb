{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e30f4fe-3274-4399-a301-1f9b52aacae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "import time\n",
    "import configparser\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "247009fc-ae81-4248-b30d-467bec15d94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download surface data and domain data if not available on machine\n",
    "def get_domain_surf_data(domain_URL,surf_URL,dirc,outFolder):\n",
    "    dirc = 'C:/Users/zahu573/D/ELM/'\n",
    "    outDir = os.path.join(dirc,outFolder)\n",
    "    try: \n",
    "        os.makedirs(outDir)\n",
    "        print(outDir)\n",
    "    except:\n",
    "        print(outDir,': path already exists')\n",
    "\n",
    "    for url in [domain_URL,surf_URL]:\n",
    "        if os.path.isfile(outDir+'/'+url.split('/')[-1])==True:\n",
    "            print('File exists')\n",
    "        else:\n",
    "            r = requests.get(url, verify=False)  \n",
    "            with open(outDir+'/'+url.split('/')[-1], 'wb') as f:\n",
    "                print(url.split('/')[-1])\n",
    "                f.write(r.content)\n",
    "    clm_gridded_domain_filename = outDir+'/'+domain_URL.split('/')[-1]\n",
    "    clm_gridded_surfdata_filename = outDir+'/'+surf_URL.split('/')[-1]\n",
    "    print('domain file: ',clm_gridded_domain_filename)\n",
    "    print('surface file: ',clm_gridded_surfdata_filename)\n",
    "        \n",
    "    return clm_gridded_domain_filename,clm_gridded_surfdata_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60cf6bee-a1e9-4e3d-8c5f-202ea9a7c7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lat_cmax: maximum lat of grid centroid\n",
    "#lat_cmin: minimum lat of grid centroid\n",
    "#lon_cmax: maximum lon of grid centroid\n",
    "#lon_cmin: minimum lon of grid centroid\n",
    "#generate the lat/lons of grid centroids in the study domain\n",
    "def create_lat_lon_list(lat_cmax,lat_cmin,lon_cmax,lon_cmin,res):\n",
    "    lat = lat_cmin\n",
    "    lon = lon_cmin\n",
    "    list_lat = [lat]\n",
    "    list_lon = [lon]\n",
    "\n",
    "    while lat<lat_cmax:\n",
    "        lat+=res\n",
    "        # print(lat)\n",
    "        list_lat.append(lat)\n",
    "    while lon<lon_cmax:\n",
    "        lon+=res\n",
    "        # print(lon)\n",
    "        list_lon.append(lon)\n",
    "    print(len(list_lat),len(list_lon),len(list_lat)*len(list_lon))\n",
    "    #make unique combinations of grid centroid lat/lons\n",
    "    permut = list(itertools.product(list_lat,list_lon))\n",
    "    lat_lon_df = pd.DataFrame(permut,columns=['lat','lon'])\n",
    "    nsites = int(len(lat_lon_df))\n",
    " \n",
    "    nsites_line = pd.DataFrame({'lat': nsites, 'lon': ''}, index=[0])\n",
    "    output_latlon_df_nsites = pd.concat([nsites_line,lat_lon_df]).reset_index(drop=True)\n",
    "    output_latlon_df = lat_lon_df\n",
    "    output_latlon_df_nsites.to_csv('C:/Users/zahu573/D/ELM/ELM_grids/%sx1_sparse_grid_latlon.txt'%str(nsites),\n",
    "                            header=None,index=False, sep=\"\\t\",float_format='%.3f' )\n",
    "    lat=output_latlon_df.lat.to_numpy()\n",
    "    lon=output_latlon_df.lon.to_numpy()\n",
    "    return lat,lon,output_latlon_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9ec8cad-9a05-40a8-aa36-178d3454f476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ComputeLatLonAtVertex(output_latlon_df,dlat,dlon):\n",
    "    latv = np.empty((len(output_latlon_df), 4))\n",
    "    lonv = np.empty((len(output_latlon_df), 4))\n",
    "    for i in range(0,len(output_latlon_df)):\n",
    "        latv[i][0] = output_latlon_df.lat[i]-dlat/2\n",
    "        latv[i][1] = output_latlon_df.lat[i]-dlat/2 \n",
    "        latv[i][2] = output_latlon_df.lat[i]+dlat/2 \n",
    "        latv[i][3] = output_latlon_df.lat[i]+dlat/2\n",
    "    for i in range(0,len(output_latlon_df)):\n",
    "        lonv[i][0] = output_latlon_df.lon[i]-dlon/2\n",
    "        lonv[i][1] = output_latlon_df.lon[i]+dlon/2 \n",
    "        lonv[i][2] = output_latlon_df.lon[i]+dlon/2 \n",
    "        lonv[i][3] = output_latlon_df.lon[i]-dlon/2\n",
    "    return latv,lonv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bca7840f-1af7-4741-8de3-f6b50c976f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PerformFractionCoverCheck(varname, data, set_natural_veg_frac_to_one):\n",
    "    if varname == 'PCT_URBAN':\n",
    "        if set_natural_veg_frac_to_one ==1:\n",
    "            data = data * 0\n",
    "        else: \n",
    "            print('set_natural_veg_frac_to_one = 0')\n",
    "    elif varname in ['PCT_CROP','PCT_WETLAND','PCT_LAKE','PCT_GLACIER']:\n",
    "        if set_natural_veg_frac_to_one ==1:\n",
    "            data = data * 0\n",
    "        else:\n",
    "            print('set_natural_veg_frac_to_one = 0')\n",
    "    elif varname == 'PCT_NATVEG':\n",
    "        if set_natural_veg_frac_to_one ==1:\n",
    "            data = data*0 + 100\n",
    "        else:\n",
    "            print('set_natural_veg_frac_to_one = 0')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "110c8ecf-7f00-4047-ae02-87a6ba71ca3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates an unstructured domain netCDF file for CLM45.\n",
    "\n",
    "# INPUT:\n",
    "#       lon_region = Vector containing longitude @ cell-center.\n",
    "#       lat_region = Vector containing latitude @ cell-center.\n",
    "#       lonv_region = Vector containing longitude @ cell-vertex.\n",
    "#       latv_region = Vector containing latitude @ cell-vertex.\n",
    "#       clm_gridded_domain_filename = Default CLM domain file name\n",
    "#       out_netcdf_dir = Directory where CLM surface dataset will be saved\n",
    "#       clm_usrdat_name = User defined name for CLM dataset\n",
    "\n",
    "def CreateCLMUgridDomainForCLM45(lat_region,lon_region,latv_region,lonv_region,\n",
    "                                clm_gridded_domain_filename, out_netcdf_dir,clm_usrdat_name):\n",
    "    nc_out_name = '%s/domain_%s_%s.nc'%(out_netcdf_dir,clm_usrdat_name,time.strftime(\"%y%m%d\"))\n",
    "    print('domain:  ',nc_out_name)\n",
    "    \n",
    "    ncid_inp = nc.Dataset(clm_gridded_domain_filename,'r')\n",
    "    ncid_out = nc.Dataset(nc_out_name, 'w', format='NETCDF4')\n",
    "    \n",
    "    ndims=len(ncid_inp.dimensions)\n",
    "    nvars=len(ncid_inp.variables)\n",
    "    nv = np.shape(latv_region)[1]\n",
    "    ni = np.shape(latv_region)[0]\n",
    "    nj = 1\n",
    "    \n",
    "    '''Define dimensions'''\n",
    "    for ii in ncid_inp.dimensions:\n",
    "        dimname = ncid_inp.dimensions[ii].name\n",
    "        ndim = len(ncid_inp.dimensions[ii])\n",
    "        # print(dimname,ndim)\n",
    "        if dimname == 'nv':\n",
    "            ndim = nv\n",
    "            nv = ncid_out.createDimension(dimname, ndim)\n",
    "        elif ii == 'ni':\n",
    "            ndim = ni    \n",
    "            ni = ncid_out.createDimension(dimname, ndim)\n",
    "        elif ii == 'nj':\n",
    "            ndim = nj\n",
    "            nj = ncid_out.createDimension(dimname, ndim)\n",
    "            \n",
    "    '''Define variables'''\n",
    "    varnames = []\n",
    "    varids = [0]*nvars\n",
    "    for (varid,ivar) in zip(range(len(varids)),ncid_inp.variables):\n",
    "        varname = ncid_inp.variables[ivar].name\n",
    "        xtype = ncid_inp.variables[ivar].dtype\n",
    "        dimids = ncid_inp.variables[ivar].dimensions\n",
    "        natts = len(ncid_inp.variables[ivar].ncattrs())\n",
    "        varnames.append(varname)\n",
    "        # print(varname)\n",
    "        varids[varid] = ncid_out.createVariable(varname,xtype,dimids)\n",
    "        for iatt in ncid_inp.variables[ivar].ncattrs():\n",
    "            attname = iatt\n",
    "            attvalue = getattr(ncid_inp.variables[ivar], iatt)\n",
    "            # print(attname, attvalue)\n",
    "            ncid_out.variables[ivar].setncattr(attname, attvalue)    \n",
    "    # print(ncid_out.variables)\n",
    "    \n",
    "    '''Set the global atrributes for output netcdf'''\n",
    "    setattr(ncid_out, 'Created_by', os.getlogin())\n",
    "    setattr(ncid_out, 'Created_on', time.strftime(\"%Y-%m-%d %H:%M:%S\")) \n",
    "    \n",
    "    '''Copy variables'''\n",
    "    for ivar in ncid_inp.variables:\n",
    "        varname = ncid_inp.variables[ivar].name\n",
    "        xtype = ncid_inp.variables[ivar].dtype\n",
    "        dimids = ncid_inp.variables[ivar].dimensions\n",
    "        natts = len(ncid_inp.variables[ivar].ncattrs())\n",
    "        if varname == 'xc':\n",
    "            data = lon_region\n",
    "            ncid_out['xc'][:] = data\n",
    "        elif varname == 'yc':\n",
    "            data = lat_region\n",
    "            ncid_out['yc'][:] = data\n",
    "        elif varname == 'xv':\n",
    "            data = lonv_region\n",
    "            ncid_out['xv'][:] = data\n",
    "        elif varname == 'yv':\n",
    "            data = latv_region\n",
    "            ncid_out['yv'][:] = data\n",
    "        elif varname == 'mask':\n",
    "            data = np.ones((len(lon_region),1))\n",
    "            ncid_out['mask'][:] = data\n",
    "        elif varname == 'frac':\n",
    "            data = np.ones((len(lon_region),1))\n",
    "            ncid_out['frac'][:] = data\n",
    "        elif varname == 'area':\n",
    "            if  lonv_region.shape[1] == 3:\n",
    "                ax = lonv_region[:,0]\n",
    "                ay = latv_region[:,0]\n",
    "                bx = lonv_region[:,1]\n",
    "                by = latv_region[:,1]\n",
    "                cx = lonv_region[:,2]\n",
    "                cy = latv_region[:,2]\n",
    "                data = 0.5*((ax*(by-cy)) + (bx*(cy-ay)) + (cx*(ay-by)))\n",
    "            elif lonv_region.shape[1] == 4:\n",
    "                data = (lonv_region[:,0]-lonv_region[:,1])*(latv_region[:,0]-latv_region[:,2])\n",
    "                # print(data)\n",
    "            else:\n",
    "                print(\"Error: Added area computation\")\n",
    "            ncid_out['area'][:] = data\n",
    "\n",
    "    ncid_out.close()\n",
    "    ncid_inp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37623d61-df9b-4454-b3ba-30be4534007a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Converts a 2D data (lat,lon) to 1D (gridcell)'''\n",
    "def sgrid_convert_2d_to_1d(vardimids, ii_idx, jj_idx, data):\n",
    "    data_2d = np.zeros(np.shape(ii_idx))\n",
    "    for ii in range(np.shape(ii_idx)[0]):\n",
    "        data_2d[ii]= data[ii_idx[ii],jj_idx[ii]]\n",
    "    # (lon,lat) --> (gridcell)\n",
    "    vardimids_new =  []\n",
    "    for x in vardimids:\n",
    "        if x in ['lsmlat','lsmlon']:\n",
    "            if x == 'lsmlat':\n",
    "                vardimids_new.append('gridcell')\n",
    "        else:\n",
    "            vardimids_new.append(x)\n",
    "    vardimids = tuple(vardimids_new)\n",
    "    dims = np.shape(data_2d)\n",
    "    if len(dims)>1:\n",
    "        dims_new = [dims[0]*dims[1]]+[dims[k] for k in range(2,len(dims))]\n",
    "        print(\"length of data_2d dim exceeds 1. Update the code\")\n",
    "    else:\n",
    "        dims_new = dims\n",
    "    data_1d = np.reshape(data_2d,dims_new)\n",
    "    return data_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22336f35-234e-4bf4-971c-7fdad2a2dade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' Converts a 2D data (gridcell,:) to 1D (gridcell,:)'''\n",
    "def ugrid_convert_2d_to_2d(ii_idx, data):\n",
    "    data_2d = data[:,ii_idx.astype(int)]\n",
    "    return data_2d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12eb84af-8371-4e4e-9cb1-4f30648e8ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Converts a 3D data (lat,lon,:) to 2D (gridcell,:)'''\n",
    "def sgrid_convert_3d_to_2d(vardimids, ii_idx, jj_idx, data):\n",
    "    nx = np.shape(ii_idx)[0]\n",
    "    try:\n",
    "        ny = np.shape(jj_idx)[1]\n",
    "    except:\n",
    "        ny = 1\n",
    "    try:\n",
    "        nz = np.shape(data)[0] \n",
    "    except:\n",
    "        nz = 1\n",
    "    # print(nx,ny,nz)\n",
    "    data_3d = np.zeros((nz,ny,nx))\n",
    "    # print(data_3d)\n",
    "    # print(np.shape(data_3d))\n",
    "    for ii in range(0,nx):\n",
    "        for jj in range(0,ny):\n",
    "            data_3d[:,0,ii] = data[:,ii_idx[ii],jj_idx[ii]]\n",
    "    vardimids_new =  []\n",
    "    for x in vardimids:\n",
    "        if x in ['lsmlat','lsmlon']:\n",
    "            if x == 'lsmlat':\n",
    "                vardimids_new.append('gridcell')\n",
    "        else:\n",
    "            vardimids_new.append(x)\n",
    "    vardimids = tuple(vardimids_new)\n",
    "    # print(vardimids)\n",
    "    dims = np.shape(data_3d)\n",
    "    # print(dims)\n",
    "    if len(dims)>2:\n",
    "        dims_new = [dims[k] for k in range(0,len(dims)-2)]+[dims[1]*dims[2]]\n",
    "        # print(dims_new)\n",
    "    else:\n",
    "        dims_new = [dims[1]*dims[2]]\n",
    "    data_2d = np.reshape(data_3d,dims_new)\n",
    "    \n",
    "    return data_2d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb058688-1df3-472e-a540-1c63222c1475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Converts a 3D data (gridcell,:,:) to 3D (gridcell,:,:)'''\n",
    "def ugrid_convert_3d_to_3d(ii_idx, data):\n",
    "    nx = np.shape(ii_idx)[0]\n",
    "    ny = np.shape(data)[1]\n",
    "    nz = np.shape(data)[0]\n",
    "    data_3d = np.zeros((nz,ny,nx))\n",
    "    for ii in range(0,nx):\n",
    "        data_3d[:,:,ii] = data[:,:,jj_idx[ii]]\n",
    "    return data_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bee0a25-34b8-4432-952c-c22188685ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Converts a 4D data (lat,lon,:,:) to 3D (gridcell,:,:)'''\n",
    "def sgrid_convert_4d_to_3d(vardimids, ii_idx, jj_idx, data):\n",
    "    nx = np.shape(ii_idx)[0]\n",
    "    try:\n",
    "        ny = np.shape(ii_idx)[1]\n",
    "    except:\n",
    "        ny = 1\n",
    "    nz = np.shape(data)[1]\n",
    "    na = np.shape(data)[0]\n",
    "    # print(nx, ny, nz,na)\n",
    "    data_4d = np.zeros((na,nz,ny,nx))\n",
    "    for ii in range(0,nx):\n",
    "        for jj in range(0,ny):\n",
    "            data_4d[:,:,0,ii] = data[:,:,ii_idx[ii],jj_idx[ii]]\n",
    "    vardimids_new =  []\n",
    "    for x in vardimids:\n",
    "        if x in ['lsmlat','lsmlon']:\n",
    "            if x == 'lsmlat':\n",
    "                vardimids_new.append('gridcell')\n",
    "        else:\n",
    "            vardimids_new.append(x)\n",
    "    vardimids = tuple(vardimids_new)\n",
    "    dims = np.shape(data_4d)\n",
    "    # print(vardimids,dims)\n",
    "    if len(dims)>2:\n",
    "        dims_new = [dims[k] for k in range(0,len(dims)-2)]+[dims[-1]*dims[-2]]\n",
    "        # print(dims_new)\n",
    "    else:\n",
    "        dims_new = [dims[-1]*dims[-2]]\n",
    "    data_3d = np.reshape(data_4d,dims_new)\n",
    "    return data_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61ea1b4c-c567-4fde-841f-6b61b5682b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates an unstructured surface-data netCDF file for CLM45.\n",
    "\n",
    "# INPUT:\n",
    "#        lati_region = Vector containing latitude @ cell-center.\n",
    "#        long_region = Vector containing longitude @ cell-center.\n",
    "#        clm_gridded_surfdata_filename = Gridded CLM surface data file\n",
    "#        out_netcdf_dir = Directory where CLM surface dataset will be saved\n",
    "#        clm_usrdat_name = User defined name for CLM dataset\n",
    "#        set_natural_veg_frac_to_one =\n",
    "\n",
    "def CreateCLMUgridSurfdatForCLM45(lati_region, long_region, clm_gridded_surfdata_filename,\n",
    "                                  out_netcdf_dir, clm_usrdat_name, surf_URL, set_natural_veg_frac_to_one, dlat,dlon):\n",
    "    nc_out_name = '%s/surfdata_%s_%s.nc'%(out_netcdf_dir,clm_usrdat_name,time.strftime(\"%y%m%d\"))\n",
    "    print('surface dataset:  ', nc_out_name)\n",
    "\n",
    "    ncid_inp = nc.Dataset(clm_gridded_surfdata_filename,'r')\n",
    "    ncid_out = nc.Dataset(nc_out_name, 'w', format='NETCDF3_64BIT_OFFSET')   \n",
    "\n",
    "    ndims=len(ncid_inp.dimensions)\n",
    "    nvars=len(ncid_inp.variables)\n",
    "    \n",
    "    '''Define dimensions'''\n",
    "    lonlat_found = 0\n",
    "    dimname_list=[0]*ndims\n",
    "    dim_list=[0]*ndims\n",
    "\n",
    "    # print(dimname_list)\n",
    "    for (idim,n) in zip(ncid_inp.dimensions,range(ndims)):\n",
    "        # print(idim,n)\n",
    "        dimname = ncid_inp.dimensions[idim].name\n",
    "        dimname_list[n] = dimname\n",
    "        dimlen = len(ncid_inp.dimensions[idim])\n",
    "        if dimname in ['lsmlon','lsmlat']:\n",
    "            if lonlat_found ==0:\n",
    "                lonlat_found = 1\n",
    "                dimname = 'gridcell'\n",
    "                dimname_list.append(dimname)\n",
    "                dimlen = len(lon_region)\n",
    "                # print(dimname,dimlen)\n",
    "                dim_list[n] = ncid_out.createDimension(dimname, dimlen)\n",
    "        elif dimname == 'time':\n",
    "            # print(dimname,dimlen)\n",
    "            dimname_list.append(dimname)\n",
    "            dim_list[n] =  ncid_out.createDimension(dimname,None);\n",
    "        elif dimname == 'gridcell':\n",
    "            dimlen = len(lon_region)\n",
    "            dimname_list.append(dimname)\n",
    "            # print('elif',dimname,dimlen)\n",
    "            dim_list[n] = ncid_out.createDimension(dimname, dimlen)\n",
    "        else:\n",
    "            # print('else',dimname,dimlen)\n",
    "            dim_list[n] = ncid_out.createDimension(dimname, dimlen)\n",
    "\n",
    "    '''Define variables'''\n",
    "    varnames = []\n",
    "    varids = [0]*nvars\n",
    "    for (varid,ivar) in zip(range(nvars),ncid_inp.variables):\n",
    "        varname = ncid_inp.variables[ivar].name\n",
    "        xtype = ncid_inp.variables[ivar].dtype\n",
    "        dimids = ncid_inp.variables[ivar].dimensions\n",
    "        natts = len(ncid_inp.variables[ivar].ncattrs())\n",
    "        if len(dimids)>0:\n",
    "            if lonlat_found==1:\n",
    "                if all(x in dimids for x in ['lsmlat', 'lsmlon']):\n",
    "                    # dimids_tup2lst = list(dimids)\n",
    "                    dimids_new=[]\n",
    "                    for x in dimids:\n",
    "                        if x in ['lsmlat','lsmlon']:\n",
    "                            if x == 'lsmlat':\n",
    "                                dimids_new.append('gridcell')\n",
    "                        else:\n",
    "                            dimids_new.append(x)\n",
    "                    dimids = tuple(dimids_new)\n",
    "        # print(dimids)\n",
    "        varnames.append(varname)\n",
    "        # print(varname)\n",
    "        varids[varid] = ncid_out.createVariable(varname,xtype,dimids)\n",
    "        for iatt in ncid_inp.variables[ivar].ncattrs():\n",
    "            attname = iatt\n",
    "            attvalue = getattr(ncid_inp.variables[ivar], iatt)\n",
    "            # print(attname, attvalue)\n",
    "            ncid_out.variables[ivar].setncattr(attname, attvalue)    \n",
    "    # print(ncid_out.variables)\n",
    "    \n",
    "    '''Set the global atrributes for output netcdf'''\n",
    "    setattr(ncid_out, 'Created_by', os.getlogin())\n",
    "    setattr(ncid_out, 'Created_on', time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    '''Find the nearest neighbor index for (long_region,lati_xy) within global dataset'''\n",
    "    #Get Lat/Lon for global 2D grid.\n",
    "    for ivar in varnames:\n",
    "        if ivar=='LATIXY':\n",
    "            latixy = ncid_inp.variables[ivar][:]\n",
    "        elif ivar=='LONGXY':\n",
    "            longxy = ncid_inp.variables[ivar][:]\n",
    "\n",
    "    #read in global pft mask 1=valid 0=invalid\n",
    "    pftmask = ncid_inp.variables['PFTDATA_MASK'][:]    \n",
    "\n",
    "    #mark invalid gridcells as [lon, lat] [-9999, -9999]\n",
    "    latixy[pftmask==0]=-9999\n",
    "    longxy[pftmask==0]=-9999\n",
    "\n",
    "    #allocate memory\n",
    "    ii_idx = np.zeros_like(lon_region)  \n",
    "    jj_idx = np.zeros_like(lon_region)\n",
    "\n",
    "    #find the index\n",
    "    for ii in range(np.shape(lon_region)[0]):\n",
    "        dist = (longxy-lon_region[ii])**2 + (latixy - lat_region[ii])**2\n",
    "        # nearest_cell_i_idx, nearest_cell_j_idx = np.unravel_index(np.argmin(dist, axis=None), dist.shape)\n",
    "        nearest_cell_i_idx, nearest_cell_j_idx = np.where((dist==dist.min()))\n",
    "        # print(nearest_cell_i_idx, nearest_cell_j_idx)\n",
    "        if len(nearest_cell_i_idx) > 1:\n",
    "            print('  WARNING: Site with (lat,lon) = (%s,%s) has more than one cells that are equidistant.' %(str(lat_region[ii]),str(lon_region[ii])))\n",
    "            print('Picking the first closest grid cell.')\n",
    "        # print(dist.min())\n",
    "        ii_idx[ii] = nearest_cell_i_idx[0]\n",
    "        jj_idx[ii] = nearest_cell_j_idx[0]\n",
    "\n",
    "    ii_idx = ii_idx.astype(int)\n",
    "    jj_idx = jj_idx.astype(int)\n",
    "    \n",
    "    '''Copy variables'''\n",
    "    for ivar in ncid_inp.variables:\n",
    "        data = ncid_inp.variables[ivar][:]\n",
    "        varname = ncid_inp.variables[ivar].name\n",
    "        vartype = ncid_inp.variables[ivar].dtype\n",
    "        vardimids = ncid_inp.variables[ivar].dimensions\n",
    "        varnatts = len(ncid_inp.variables[ivar].ncattrs())\n",
    "        if varname == 'LATIXY':\n",
    "            # print('latixy')\n",
    "            ncid_out['LATIXY'][:] = lat_region\n",
    "        elif varname == 'LONGXY':\n",
    "            # print('lonxy')\n",
    "            ncid_out['LONGXY'][:] = lon_region \n",
    "        elif varname == 'AREA':\n",
    "            AREA = np.empty_like(lon_region)\n",
    "            AREA.fill((111.1*dlat)*(111.1*dlon))\n",
    "            ncid_out['AREA'][:] = AREA \n",
    "        else:\n",
    "            if len(vardimids)==0:\n",
    "                print('vardimids length 0',varname)\n",
    "                ncid_out[ivar][:] = data\n",
    "            elif len(vardimids)==1:\n",
    "                print('vardimids length 1',varname)\n",
    "                if lonlat_found==1:\n",
    "                    data=0\n",
    "                else:\n",
    "                    if vardimids == 'lsmlat':\n",
    "                        # print(vardimids)\n",
    "                        data = data[ii_idx.astype(int)]\n",
    "                        # print(data)\n",
    "                    else:\n",
    "                        data = 0\n",
    "                ncid_out[ivar][:] = data\n",
    "            elif len(vardimids)==2:\n",
    "                print('vardimids length 2',varname)\n",
    "                if 'lsmlat' in vardimids:\n",
    "                    if lonlat_found==1:\n",
    "                        # print((varname, vardimids,np.shape(data)))\n",
    "                        data_1d = sgrid_convert_2d_to_1d(vardimids, ii_idx, jj_idx, data)\n",
    "                        data_new = PerformFractionCoverCheck(varname, data_1d, set_natural_veg_frac_to_one)\n",
    "                    else:\n",
    "                        data_2d = ugrid_convert_2d_to_2d(ii_idx, data)\n",
    "                        data_new = PerformFractionCoverCheck(varname, data_2d, set_natural_veg_frac_to_one)\n",
    "                    ncid_out[ivar][:] = data_new\n",
    "                else:\n",
    "                    # print('else case 2')\n",
    "                    ncid_out[ivar][:] = data\n",
    "\n",
    "            elif len(vardimids)==3:\n",
    "                print('vardimids length 3',varname)\n",
    "                if 'lsmlat' in vardimids:\n",
    "                    if lonlat_found==1:\n",
    "                        # print(varname, vardimids,np.shape(data))\n",
    "                        data_2d  = sgrid_convert_3d_to_2d(vardimids, ii_idx, jj_idx, data)\n",
    "                        data_new = PerformFractionCoverCheck(varname, data_2d, set_natural_veg_frac_to_one)\n",
    "                        ncid_out[ivar][:] = data_new        \n",
    "                    else:\n",
    "                        # print('case 3 else')\n",
    "                        data_3d  = ugrid_convert_3d_to_3d(ii_idx, data)\n",
    "                        data_new = PerformFractionCoverCheck(varname, data_3d, set_natural_veg_frac_to_one)\n",
    "                        ncid_out[ivar][:] = data_new \n",
    "                else:\n",
    "                    # print('no latlon')\n",
    "                    ncid_out[ivar][:] = data                    \n",
    "            elif len(vardimids)==4:\n",
    "                print('vardimids length 4',varname)\n",
    "                if 'lsmlat' in vardimids:\n",
    "                    if lonlat_found==1:\n",
    "                        # print(varname,np.shape(data))\n",
    "                        data_3d = sgrid_convert_4d_to_3d(vardimids, ii_idx, jj_idx, data)\n",
    "                    else:\n",
    "                        print('error')\n",
    "                    ncid_out[ivar][:] = data_3d \n",
    "                else:\n",
    "                    print('else vardimids length 4')\n",
    "                    ncid_out[ivar][:] = data \n",
    "            else:\n",
    "                print('error')\n",
    "    ncid_out.close()\n",
    "    ncid_inp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6264acd5-246f-4fd5-8b9e-9d04da3f7898",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading domain and surface netcdfs if missing\n",
      "C:/Users/zahu573/D/ELM/clm-netcdf : path already exists\n",
      "File exists\n",
      "File exists\n",
      "domain file:  C:/Users/zahu573/D/ELM/clm-netcdf/domain.lnd.fv1.9x2.5_USGS.110713.nc\n",
      "surface file:  C:/Users/zahu573/D/ELM/clm-netcdf/surfdata_1.9x2.5_simyr2000_c141219.nc\n",
      "Calculating Lat/lon for grid center\n",
      "25 47 1175\n",
      "1175x1_sparse_grid\n",
      "Calculating lat/lon vertex\n",
      "Creating CLM domain\n",
      "domain:   C:/Users/zahu573/D/ELM/clm-netcdf/domain_1175x1_sparse_grid_231025.nc\n",
      "Creating CLM surface dataset\n",
      "surface dataset:   C:/Users/zahu573/D/ELM/clm-netcdf/surfdata_1175x1_sparse_grid_231025.nc\n",
      "vardimids length 0 mxsoil_color\n",
      "vardimids length 2 SOIL_COLOR\n",
      "vardimids length 3 PCT_SAND\n",
      "vardimids length 3 PCT_CLAY\n",
      "vardimids length 3 ORGANIC\n",
      "vardimids length 2 FMAX\n",
      "vardimids length 1 natpft\n",
      "vardimids length 2 LANDFRAC_PFT\n",
      "vardimids length 2 PFTDATA_MASK\n",
      "vardimids length 2 PCT_NATVEG\n",
      "set_natural_veg_frac_to_one = 0\n",
      "vardimids length 2 PCT_CROP\n",
      "set_natural_veg_frac_to_one = 0\n",
      "vardimids length 3 PCT_NAT_PFT\n",
      "vardimids length 4 MONTHLY_LAI\n",
      "vardimids length 4 MONTHLY_SAI\n",
      "vardimids length 4 MONTHLY_HEIGHT_TOP\n",
      "vardimids length 4 MONTHLY_HEIGHT_BOT\n",
      "vardimids length 1 time\n",
      "vardimids length 2 EF1_BTR\n",
      "vardimids length 2 EF1_FET\n",
      "vardimids length 2 EF1_FDT\n",
      "vardimids length 2 EF1_SHR\n",
      "vardimids length 2 EF1_GRS\n",
      "vardimids length 2 EF1_CRP\n",
      "vardimids length 3 CANYON_HWR\n",
      "vardimids length 3 EM_IMPROAD\n",
      "vardimids length 3 EM_PERROAD\n",
      "vardimids length 3 EM_ROOF\n",
      "vardimids length 3 EM_WALL\n",
      "vardimids length 3 HT_ROOF\n",
      "vardimids length 3 THICK_ROOF\n",
      "vardimids length 3 THICK_WALL\n",
      "vardimids length 3 T_BUILDING_MAX\n",
      "vardimids length 3 T_BUILDING_MIN\n",
      "vardimids length 3 WIND_HGT_CANYON\n",
      "vardimids length 3 WTLUNIT_ROOF\n",
      "vardimids length 3 WTROAD_PERV\n",
      "vardimids length 4 ALB_IMPROAD_DIR\n",
      "vardimids length 4 ALB_IMPROAD_DIF\n",
      "vardimids length 4 ALB_PERROAD_DIR\n",
      "vardimids length 4 ALB_PERROAD_DIF\n",
      "vardimids length 4 ALB_ROOF_DIR\n",
      "vardimids length 4 ALB_ROOF_DIF\n",
      "vardimids length 4 ALB_WALL_DIR\n",
      "vardimids length 4 ALB_WALL_DIF\n",
      "vardimids length 4 TK_ROOF\n",
      "vardimids length 4 TK_WALL\n",
      "vardimids length 4 TK_IMPROAD\n",
      "vardimids length 4 CV_ROOF\n",
      "vardimids length 4 CV_WALL\n",
      "vardimids length 4 CV_IMPROAD\n",
      "vardimids length 3 NLEV_IMPROAD\n",
      "vardimids length 2 peatf\n",
      "vardimids length 2 abm\n",
      "vardimids length 2 gdp\n",
      "vardimids length 2 SLOPE\n",
      "vardimids length 2 STD_ELEV\n",
      "vardimids length 2 binfl\n",
      "vardimids length 2 Ws\n",
      "vardimids length 2 Dsmax\n",
      "vardimids length 2 Ds\n",
      "vardimids length 2 LAKEDEPTH\n",
      "vardimids length 2 F0\n",
      "vardimids length 2 P3\n",
      "vardimids length 2 ZWT0\n",
      "vardimids length 2 PCT_WETLAND\n",
      "set_natural_veg_frac_to_one = 0\n",
      "vardimids length 2 PCT_LAKE\n",
      "set_natural_veg_frac_to_one = 0\n",
      "vardimids length 2 PCT_GLACIER\n",
      "set_natural_veg_frac_to_one = 0\n",
      "vardimids length 1 GLC_MEC\n",
      "vardimids length 3 PCT_GLC_MEC\n",
      "vardimids length 3 PCT_GLC_MEC_GIC\n",
      "vardimids length 3 PCT_GLC_MEC_ICESHEET\n",
      "vardimids length 2 PCT_GLC_GIC\n",
      "vardimids length 2 PCT_GLC_ICESHEET\n",
      "vardimids length 3 TOPO_GLC_MEC\n",
      "vardimids length 2 TOPO\n",
      "vardimids length 3 PCT_URBAN\n",
      "set_natural_veg_frac_to_one = 0\n",
      "vardimids length 2 URBAN_REGION_ID\n"
     ]
    }
   ],
   "source": [
    "print('Downloading domain and surface netcdfs if missing')\n",
    "domain_URL='https://svn-ccsm-inputdata.cgd.ucar.edu/trunk/inputdata/share/domains/domain.clm/domain.lnd.fv1.9x2.5_USGS.110713.nc'\n",
    "surf_URL='https://svn-ccsm-inputdata.cgd.ucar.edu/trunk/inputdata/lnd/clm2/surfdata_map/surfdata_1.9x2.5_simyr2000_c141219.nc'\n",
    "''' Another url for surface data: https://web.lcrc.anl.gov/public/e3sm/inputdata/lnd/clm2/surfdata_map/'''\n",
    "dirc = 'C:/Users/zahu573/D/ELM/'\n",
    "outFolder = 'clm-netcdf'\n",
    "clm_gridded_domain_filename,clm_gridded_surfdata_filename = get_domain_surf_data(domain_URL,surf_URL,dirc,outFolder)\n",
    "\n",
    "print('Calculating Lat/lon for grid center')\n",
    "#setting the max and min lat/lons and resolution \n",
    "#Upper Wenas\n",
    "# lat_cmax = 47.05416667\n",
    "# lat_cmin = 46.7375\n",
    "# lon_cmax = 239.35416667 \n",
    "# lon_cmin = 239.0125\n",
    "\n",
    "#American River\n",
    "lat_cmax = 46.99583334\n",
    "lat_cmin = 46.80416667\n",
    "lon_cmax = 238.8458333\n",
    "lon_cmin = 238.4708333\n",
    "\n",
    "res = 0.025/3\n",
    "\n",
    "lat_region,lon_region,output_latlon_df =create_lat_lon_list(lat_cmax,lat_cmin ,lon_cmax,lon_cmin,res)\n",
    "\n",
    "#define grid size in degrees\n",
    "dlat = 0.025/3  \n",
    "dlon = 0.025/3 \n",
    "\n",
    "#The name that will be used to for the sparse surface dataset domain file.\n",
    "clm_usrdat_name = str(len(output_latlon_df))+'x1_sparse_grid'\n",
    "print(clm_usrdat_name)\n",
    "set_natural_veg_frac_to_one = 0\n",
    "\n",
    "print('Calculating lat/lon vertex')\n",
    "latv_region,lonv_region =ComputeLatLonAtVertex(output_latlon_df,dlat,dlon)\n",
    "\n",
    "out_netcdf_dir=dirc+outFolder\n",
    "print('Creating CLM domain')\n",
    "domain_nc = CreateCLMUgridDomainForCLM45(lat_region,lon_region,latv_region,lonv_region,\n",
    "                                clm_gridded_domain_filename, out_netcdf_dir,clm_usrdat_name)\n",
    "print('Creating CLM surface dataset')\n",
    "fsurdat = CreateCLMUgridSurfdatForCLM45(lat_region,lon_region, clm_gridded_surfdata_filename, out_netcdf_dir,\n",
    "                                        clm_usrdat_name,surf_URL, set_natural_veg_frac_to_one,dlat,dlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735111c5-9f7f-4190-906e-194b9ef77b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
